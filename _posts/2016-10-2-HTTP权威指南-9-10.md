---
layout: post
title: HTTP权威指南-9-10
excerpt: 第九章 Web机器人; 第十章 HTTP-NG
category: CS
---

* TOC
{:toc}


#### 第九章 Web机器人
##### 爬虫及爬行方式
- 从哪儿开始: 根集
- 链接的提取以及相对链接的标准化
- 避免环路出现
- 循环与复制
> ⚠️ 如果爬虫不断地获取相同的页面时，并且爬虫与服务器连接良好，它就可能会阻止其他真实用户的访问，这种拒绝服务是可以作为法律诉讼理由的。

- 面包屑留下的痕迹;大规模Web爬虫对其访问地址进行管理时使用以下相关技术点:
1. 树和散列表(加速URL查找)
2. 有损的存在位图(减小空间)
3. 检查点(将已访问URL列表存在硬盘上，防止机器人程序崩溃)
4. 分类

- 别名与机器人环路
- 规范化URL
1. 如果没有指定端口的话，就向主机名中添加 '80'
2. 将所有转义符 %xx 都转换成等价字符
3. 删除 # 标签

- 文件系统连接环路 '/'
- 动态虚拟Web空间
- 避免循环和重复
> 1. 规范化URL
> 2. 广度优先的爬行
> 3. 节流
> 4. 限制URL的大小
> 5. URL/站点黑名单
> 6. 模式检测
> 7. 内容指纹
> 8. 人工监视

##### 机器人的HTTP
- 识别请求首部
- 虚拟主机，实现机器人要支持Host首部
- 条件请求
- 对响应的处理;需要识别比如状态码，实体等
- User-agent导向

##### 行为不当的机器人
- 失控机器人
- 实效的URL
- 很长的错误URL
- 爱打听的机器人
- 动态网关访问

##### 拒绝机器人访问
- 拒绝机器人访问标准; Dissallow/Allow
- Web站点和robots.txt文件
> 1. User-agent: <robot-name>
> 2. Dissallow
> 3. Allow

- 缓存和robots.txt的过期
- HTML的robot-control元标签

##### 搜索引擎

[Web机器人](http://www.robotstxt.org)
[搜索引擎世界](http://www.searchengineworld.com)


#### 第十章 HTTP-NG 下一代系统
##### HTTP发展中存在的问题
1. 复杂性
2. 扩展性
3. 性能
4. 传输依赖性

###### 模块化及功能增强(modularize and enhance)
