---
layout: post
title: 一致性哈希算法
excerpt: 一致性哈希算法
category: Architecture
---

> 学习笔记

## 一致性哈希算法
- 什么是一致性hash算法？一致性哈希算法是为了解决传统哈希取模法在扩容缩容后需要重建所有映射的问题而设计的，是一种用到了哈希算法的数据分布策略，映射关系是多对 1，多个 Key 映射到 1 个Value上，Value 通常都是分布式系统中的某个服务节点

### 使用场景
- 比如，群聊消息系统中，如果能将同一个群的实时消息路由到同一台服务器再集中转发和存储，能极大程度避免不同服务链路之间的网络差异造成的消息顺序错乱问题.
- 哈希策略不是用来实现负载均衡的，负载均衡层面另有其他手段。这里讲的哈希策略主要是因为在某些系统中，如群聊系统、长连接系统、分布式数据库、消息队列等，有对请求部分有序性的要求，所以在这些场景下，需要使用哈希策略。哈希策略在扩容缩容场景下又有不足，所以需要引用一致性哈希。举个例子，在分布式数据库中，如果不用哈希策略而是用随机策略去选择哪一台机器，那么第一次写数据时数据写到了A机器，第二次读请求时请求到了B机器，而实际数据是存在A机器的，就会导致第二次的请求必须再发生一次B->A的RPC，这样性能就会大幅下降。

### 哈希路由的影响
- 服务器节点，动态扩缩容量问题。而在路由策略上不仅考虑读写性能问题，也要考虑阔缩容带来的影响，一致性哈希可以解决扩缩容问题。

### 假设现在情况是：node0～node1，node1～node2，node2～node0，环状，所有key数据命中区间后，都是在后一个节点存储。举例：key命中node1～node2，则数据存储在node2
- 机器扩容影响：假设在node1～node2上扩容一台机器node3，则需要将node2中部分数据迁移到node3
- 机器缩容影响：假设node3缩容，则需要将node3数据迁移node2。基于扩容之后到情况缩容。

### 数据倾斜：node节点少，极端情况哈希结果总是在某个node节点上
- 影响：节点请求量大，数据量大，机器负载高，压力大，对整个集群稳定性产生影响。另外如果大节点宕机需要迁移的数据量大，IO，带宽压力大，读写请求产生影响。

### 虚拟节点：解决数据倾斜问题
- 虚拟节点设置多少合适？越多压力越分散，数据越分散，不过还要具体问题具体分析

### 一致性哈希设计
- key vs 映射节点的哈希函数要分布的足够随机，高频使用，性能不能太差。Guava中MurmurHash函数。
- 构建一个有序哈希环：TreeMap

### 关注问题：
- 分享一个微博平台使用一致性hash 带来的问题架构是 多级 memcache 缓存，一级穿透后到二级，二级穿透后到三级，一开始使用一致性hash，但是A 节点有可能因为网络抖动暂时不通，导致本身要到 A 节点的 key到了后面的节点B上，等网络通了后，又恢复到了A节点更新用户关注列表时，本身用户关注列表在A节点，网络抖动后到了B节点，B节点cache miss，穿透到下级获取和更新了关注列表后再回写到 B 节点，等A 节点网络恢复正常，再次取关注列表时，是从 A 节点取到的脏数据




```java
package com.kuaishou.is.procurement.receive.service;

import com.google.common.hash.HashFunction;
import com.google.common.hash.Hashing;

import java.security.InvalidParameterException;
import java.util.*;

public class ConsistentHashRing {

    private static final String IPV4_REGEX = "(([0,1]?\\d?\\d|2[0-4]\\d|25[0-5])\\.){3}([0,1]?\\d?\\d|2[0-4]\\d|25[0-5])";
    private static final HashFunction HASH_FUNCTION = Hashing.murmur3_32();
    private final int virtualNodeSize;
    private final SortedMap<Integer, String> virtualHashRing;


    /**
     * 构建虚拟节点哈希环，实际存储的时候用的SortedMap，首尾没有相连，记录下首尾节点的哈希值，后续让所有介于首尾之间的Key都命中首节点，即构成了逻辑上的环形空间
     */
    private ConsistentHashRing(int virtualNodeSize, List<String> realNodeIpList) {
        this.virtualNodeSize = virtualNodeSize;
        virtualHashRing = new TreeMap<>(Comparator.comparingInt(o -> o));
        for (String ip : realNodeIpList) {
            addNode(ip);
        }
        System.out.println("init hash ring success ring=" + virtualHashRing);
    }


    public String getNodeIp(String partitionKey) {
        if (partitionKey == null || "".equals(partitionKey)) {
            throw new InvalidParameterException("partitionKey can't be empty!");
        }
        int keyCode = hash(partitionKey);
        if (keyCode > virtualHashRing.lastKey() || keyCode <= virtualHashRing.firstKey()) {
            // 哈希值介于首尾节点之间的Key都命中首节点
            return getNodeIpFromVNode(virtualHashRing.get(virtualHashRing.firstKey()));
        }
        // 从virtualHashRing中找出第一个节点哈希值大于等于key哈希值的节点
        Integer nodeHashCode = virtualHashRing.tailMap(keyCode).firstKey();
        return getNodeIpFromVNode(virtualHashRing.get(nodeHashCode));
    }

    private String getNodeIpFromVNode(String vNodeName) {
        return vNodeName.split("-")[0];
    }

    public void addNode(String ipv4Str) {
        for (int i = 0; i < virtualNodeSize; i++) {
            String vNodeName = ipv4Str + "-" + i;
            int vNodeHashCode = hash(vNodeName);
            virtualHashRing.put(vNodeHashCode, vNodeName);
        }
        // TODO 实现算法时没有数据迁移过程，实际应用中，这里还要触发扩容迁移数据机制，从其他节点迁移数据到新增的节点
    }


    public void removeNode(String ipv4Str) {
        for (int i = 0; i < virtualNodeSize; i++) {
            String vNodeName = ipv4Str + "-" + i;
            int vNodeHashCode = hash(vNodeName);
            virtualHashRing.remove(vNodeHashCode);
        }
        // TODO 实现算法时没有数据迁移过程，实际应用中，这里还要触发备份恢复机制，从备份节点里迁移数据到其它节点
    }

    /**
     * 哈希运算规则为MurmurHash_32算法，取值范围为[Integer.MIN_VALUE,Integer.MAX_VALUE]
     * 选取MurmurHash_32是因为该算法分布非常均匀，即使key非常接近，得出的hashCode也能差距很大。并且哈希code总体会均匀的分布到整个Integer空间
     *
     * @return Integer范围内的任意一个哈希值
     */
    private int hash(String key) {
        return HASH_FUNCTION.hashUnencodedChars(key).asInt();
    }

    public static class ConsistentHashRingBuilder {

        private int virtualNodeSize = 2;
        private List<String> realNodeIpList = Collections.emptyList();


        private ConsistentHashRingBuilder() {
        }

        public static ConsistentHashRingBuilder builder() {
            return new ConsistentHashRingBuilder();
        }

        public ConsistentHashRingBuilder virtualNodeSize(int virtualNodeSize) {
            this.virtualNodeSize = virtualNodeSize;
            return this;
        }

        public ConsistentHashRingBuilder realNodeIpList(List<String> realNodeIpList) {
            this.realNodeIpList = realNodeIpList;
            return this;
        }

        public ConsistentHashRing build() {
            if (virtualNodeSize < 2) {
                throw new InvalidParameterException("virtualNodeSize must > 1");
            }
            if (realNodeIpList == null || realNodeIpList.isEmpty()) {
                throw new InvalidParameterException("realNodeIpList is empty");
            }
            if (realNodeIpList.stream().anyMatch(ipStr -> !validIpv4(ipStr))) {
                throw new InvalidParameterException("contains invalid ip");
            }
            return new ConsistentHashRing(virtualNodeSize, realNodeIpList);
        }

    }


    private static boolean validIpv4(String ipv4) {
        return Optional.ofNullable(ipv4).orElse("").matches(IPV4_REGEX);
    }


    public static void main(String[] args) {
        List<String> realNodeIpList = new ArrayList<>();
        realNodeIpList.add("192.0.0.0");
        realNodeIpList.add("192.0.0.1");
        realNodeIpList.add("192.0.0.2");
        ConsistentHashRing ring = ConsistentHashRingBuilder.builder()
                .virtualNodeSize(4)
                .realNodeIpList(realNodeIpList)
                .build();
        System.out.println("key=A should get from node:" + ring.getNodeIp("A"));
        System.out.println("key=B should get from node:" + ring.getNodeIp("B"));
        System.out.println("key=C should get from node:" + ring.getNodeIp("C"));
        System.out.println("key=D should get from node:" + ring.getNodeIp("D"));
        System.out.println("key=E should get from node:" + ring.getNodeIp("E"));
        System.out.println("key=F should get from node:" + ring.getNodeIp("F"));
        ring.removeNode("192.0.0.1");
        System.out.println("after remove node 192.0.0.1");
        System.out.println("key=A should get from node:" + ring.getNodeIp("A"));
        System.out.println("key=B should get from node:" + ring.getNodeIp("B"));
        System.out.println("key=C should get from node:" + ring.getNodeIp("C"));
        System.out.println("key=D should get from node:" + ring.getNodeIp("D"));
        System.out.println("key=E should get from node:" + ring.getNodeIp("E"));
        System.out.println("key=F should get from node:" + ring.getNodeIp("F"));
        ring.addNode("192.0.0.1");
        System.out.println("after add node 192.0.0.1");
        System.out.println("key=A should get from node:" + ring.getNodeIp("A"));
        System.out.println("key=B should get from node:" + ring.getNodeIp("B"));
        System.out.println("key=C should get from node:" + ring.getNodeIp("C"));
        System.out.println("key=D should get from node:" + ring.getNodeIp("D"));
        System.out.println("key=E should get from node:" + ring.getNodeIp("E"));
        System.out.println("key=F should get from node:" + ring.getNodeIp("F"));
    }
}
```


### 固定哈希槽与一致性哈希：Redis
- redis 缓存采用了固定哈希槽的方式维护 Key 和存储节点的关系。每个节点负责一部分槽，槽的总数是固定的 16384，无论节点数怎么变， Key 进行哈希运算再对槽总数取模的值都是不变的。

### 一致性哈希算法的应用非常广泛，在分布式数据库 Cassandra 、缓存Memcache、分布式服务框架Dubbo中都有应用。
