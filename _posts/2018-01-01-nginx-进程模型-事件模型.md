---
layout: post
title: Nginx-进程模型-事件模型
excerpt: Nginx-进程模型-事件模型
category: Nginx
---

#### Nginx-进程模型以及事件模型

- 优势:廉价；可扩展性；增加吞吐量；灵活性；可用性；大量并发请求发散到多台节点分别处理，减少用户等待时间。其次单个负载运算分担到多台节点设备上，每台设备处理结束后，将结果汇总返回，系统的处理能力得到大幅的提高。
- 解决的问题: 如果一个请求产生一个线程来处理，那么线程数就是并发数，那么显而易见的，就是会有很多线程在等待中。等什么？最多的应该是等待网络传输。并且这么多的线程造成CPU的上下文的切换，造成性能瓶颈(比如Tomcat)。而Nginx异步非阻塞，每个请求花费在请求上的时间片不多。这就解决了高并发的问题。异步，非阻塞，使用epoll，和大量细节处的优化。webserver刚好属于网络io密集型应用，不算是计算密集型。

##### 进程模型: Master/Worker
- 进程模型: Master/Worker，一个Master进程生成一个或多个Worker进程。Master进程主要用来管理Worker进程，包含接收外界的信号，向各个Worker发送信号，监控Worker进程的运行状态，当Worker进程退出后(异常情况下)会自动重新启动新的Worker进程，而基本的网络事件都是放在Worker进程中来处理，多个Worker进程之间是对等的，它们同时来竞争来客户端的请求，各个进程之间相互独立，Worker进程个数一般与CPU核数保持一致，Nginx提供了`cpu亲缘性`的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效 ，这些都与Nginx的进程模型与事件模型有关
- 每个Worker都是从Master进程fork产生的，在Master里先建立好了listen的socket，然后做的fork产生多个Worker，这样每个Worker都可以进行accept这个socket。当一个请求过来以后，所有的Worker都会接收到一个信号通知，而只有一个Worker进程能进行处理，其他的Worker则将处理失败，这就是`惊群现象`.Nginx在这种情况下，新增了 `accept_mutex`(可控项,默认打开),就是一个accept的共享锁，这样同一时刻就只有一个Worker能处理请求了。当一个Worker进程accept这个请求之后，则进行读取请求-》解析请求-》处理请求-》产生结果并返回给请求方，最后断开。一个请求只有一个Worker进程来进行处理。
- master进程通过socketpair向worker子进程发送命令，终端也可以向master发送各种命令，子进程通过发送信号给master进程的方式与其通信，worker之间通过unix套接口通信。

![进程模型][https://github.com/MichaelYgZhang/michaelygzhang.github.io/blob/master/images/nginx01.png]

##### 事件模型
- Web服务器的事件通常有三种机制: 网络事件，信号，定时器
- 事件驱动：通信机制采用epoll模型，支持更大的并发连接。
- Nginx的事件处理模型

```js
while (true) {
    for t in run_tasks:
        t.handler();
    update_time(&now);
    timeout = ETERNITY;
    for t in wait_tasks:
        if (t.time <= now) {
            t.timeout_handler();
        } else {
            timeout = t.time - now;
            break;
        }
    nevents = poll_function(events, timeout);
    for i in nevents:
        task t;
    if (events[i].type == READ) {
        t.handler = read_handler;
    } else (events[i].type == WRITE) {
        t.handler = write_handler;
    }
    run_tasks_add(t);
}
```

![Nginx](https://github.com/MichaelYgZhang/michaelygzhang.github.io/blob/master/images/nginx02.png)

###### 类比Tomcat：
- 对tomcat来说，每一个进来的请求(request)都需要一个线程，直到该请求结束。如果同时进来的请求多于当前可用的请求处理线程数，额外的线程就会被创建，直到到达配置的最大线程数(maxThreads属性值)。如果仍就同时接收到更多请求，这些来不及处理的请求就会在Connector创建的ServerSocket中堆积起来，直到到达最大的配置值(acceptCount属性值)。至此，任何再来的请求将会收到connection refused错误，直到有可用的资源来处理它们。
- 这里我们关心的是tomcat能同时处理的请求数和请求响应时间，显然Connector元素的maxThreads和acceptCount属性对其有直接的影响。无论acceptCount值为多少，maxThreads直接决定了实际可同时处理的请求数。而不管maxThreads如何，acceptCount则决定了有多少请求可等待处理。然而，不管是可立即处理请求还是需要放入等待区，都需要tomcat先接受该请求(即接受client的连接请求，建立socketchannel)，那么tomcat同时可建立的连接数(maxConnections属性值)也会影响可同时处理的请求数。
